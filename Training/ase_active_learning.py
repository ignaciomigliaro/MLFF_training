from ase.io import read,write
import os
import argparse
from chgnet.model.dynamics import CHGNetCalculator
from chgnet.model import CHGNet
import contextlib
import numpy as np 
import matplotlib.pyplot as plt
import pickle
from tqdm import tqdm
import torch
import warnings
from ase.io.lammpsdata import read_lammps_data
from mace.calculators import MACECalculator
import logging
import pdb

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

"""
This code is for running an agnostic active learning workflow that works on any MLFF that has an ASE calculator and configuration space generated by molecular dynamics. 
The idea is to have a general workflow that can be used to benchmark any MLFF.
"""

# A dictionary to map calculator names to actual ASE calculator classes
# TO-DO make active learning work on all types of MLFF
CALCULATOR_MAP = {
    'ALIGNN': 'alignn.ase.ALIGNN',  # String representation of the import path
    'CHGnet': 'from chgnet.model.dynamics import CHGNetCalculator',
    'DEEPMD-kit': 'deepmd.ase.DeepMD',
    'MG3NET': 'mg3net.ase.MG3Net',
    'MACE': 'mace.ase.MACE',
}
    
def parse_arguments():
        parser = argparse.ArgumentParser(description="Active learning with MLFF for crystal structures.")
        parser.add_argument("--filepath", type=str, required=True, help="Path to the configuration file or directory.")
        parser.add_argument("--stepsize", type=int, default=1, help="Step size for loading configurations.")
        parser.add_argument("--model_dir", type=str, required=True, help="Directory containing trained models.")
        parser.add_argument("--calculator", type=str, required=True, help="Calculator to use (e.g., chgnet, some_other_calculator).")
        parser.add_argument("--device", type=str, default="cpu", help="Device to use for computation (e.g., cpu or cuda).")
        parser.add_argument("--dft_software", type=str, choices=["qe"], required=False,help="DFT software to use. Currently only 'quantum_espresso' is supported.")
        parser.add_argument("--threshold", type=float, default=None, help="User-defined threshold for filtering structures.")
        parser.add_argument("--plot_std_dev", action="store_true", help="Flag to plot the distribution of standard deviations.")
        parser.add_argument("--output_dir", type=str, default="qe_outputs", help="Directory to save Quantum Espresso files.")
        parser.add_argument('--use_cache', type=str, default=None, help='Path to cache file for storing/loading energy and std_dev data')
        parser.add_argument('--eval_criteria', type=str, choices=['energy','forces'],default='energy', help='Evaluation criteria for filtering structures choices are energy or forces')
        parser.add_argument('--lower_threshold', type=float, default=None, help='Lower threshold for filtering structures based on forces (eV/Angstrom) or energy (eV)')
        return parser.parse_args()

def map_atomic_numbers(atoms_list, Z_of_type):
    for atoms in atoms_list:
        # Get the current atomic numbers
        current_atomic_numbers = atoms.get_atomic_numbers()
        
        # Map the atomic numbers using Z_of_type
        new_atomic_numbers = [Z_of_type.get(num, 0) for num in current_atomic_numbers]
        
        # Set the new atomic numbers
        atoms.set_atomic_numbers(new_atomic_numbers)
    return atoms_list

def get_configuration_space(path, stepsize=1, Z_of_type=None, **kwargs):
    """
    Reads configurations from a file or all files in a directory using ASE's read function.
    Specifically handles `.lmp` files.

    Parameters:
    - path (str): The path to a file or directory. If a directory, all files inside will be read.
    - stepsize (int): The step size for subsampling configurations.
    - Z_of_type (dict[int, int], optional): Mapping from LAMMPS atom types to atomic numbers.
    - kwargs: Additional arguments for `read` function.

    Returns:
    - configurations (list): A list of ASE Atoms objects representing different configurations.
    """
    configurations = []

    def process_file(file_path):
        # Read configurations from the file (LAMMPS or other formats)
        atoms_list = read(file_path, index=':')  # Read all configurations from the file
        if Z_of_type:
            atoms_list = map_atomic_numbers(atoms_list, Z_of_type)  # Map atomic numbers if Z_of_type is provided
        
        # Set the file path and configuration index in the info dictionary for each Atoms object
        for i, atoms in enumerate(atoms_list):
            atoms.info['filepath'] = file_path  # Save the file path in the 'filepath' key of the info dictionary
            atoms.info['config_index'] = i  # Save the configuration index in the 'config_index' key
        
        return atoms_list

    if os.path.isfile(path):
        # Single file processing
        configurations = process_file(path)[::stepsize]  # Subsample using the stepsize
    elif os.path.isdir(path):
        # Directory processing
        for filename in os.listdir(path):
            file_path = os.path.join(path, filename)
            if os.path.isfile(file_path):
                configurations.extend(process_file(file_path)[::stepsize])  # Subsample using the stepsize
    else:
        raise ValueError(f"The provided path '{path}' is neither a file nor a directory.")

    return configurations



def load_models(model_dir, calculator='chgnet', device='cuda', extension='.pth.tar',):
    """
    Load CHGNet models from a specified directory, suppress output, and handle loading errors.

    Parameters:
    - model_dir (str): Directory containing model files.
    - device (str): Device to use for loading models (e.g., 'cpu' or 'cuda').
    - extension (str): File extension to filter model files (default is '.pth.tar').

    Returns:
    - models (list): List of loaded CHGNet models.
    """
    if calculator == 'chgnet':
        models = []
        for filename in os.listdir(model_dir):
            if filename.endswith(extension):
                model_path = os.path.join(model_dir, filename)
                try:
                    # Suppress output during model loading
                    with open(os.devnull, 'w') as fnull:
                        with contextlib.redirect_stdout(fnull):
                            loaded_model = CHGNet.from_file(
                                model_path,
                                use_device=device,
                                check_cuda_mem=False,
                                verbose=False
                            )
                    models.append(loaded_model)
                except Exception as e:
                    logging.error(f"Failed to load model from {model_path}: {e}")
    #TODO
    if calculator == 'mace':        
        models = []
        extension = '.model' 
        for filename in os.listdir(model_dir):
            if filename.endswith(extension):
                loaded_model = os.path.join(model_dir, filename)
                models.append(loaded_model)      
        logging.info(f"Successfully loaded {len(models)} models.")
    return models

def assign_calculator(configurations, models, device='cuda',calculator='chgnet'):
    """
    Create a list of configurations for each model, assign calculators, and optionally cache the results.

    Parameters:
    - configurations (list): Original list of ASE Atoms objects (the base configuration).
    - models (list): List of CHGNet models to use for creating configurations.
    - device (str): Device to use for calculation (e.g., 'cpu' or 'cuda').

    Returns:
    - all_configurations (list): List of lists where each inner list corresponds to configurations for a single model.
    """
    all_configurations = []

    if calculator == 'chgnet':
        for model in models:
            calculator = CHGNetCalculator(model=model, use_device=device)
            config_copy = [atoms.copy() for atoms in configurations]
            for atoms in config_copy:
                atoms.calc = calculator
            all_configurations.append(config_copy)
    
    if calculator == 'mace':
        for model in models:
            calculator = MACECalculator(model_paths=[model], device=device)
            config_copy = [atoms.copy() for atoms in configurations]
            for atoms in config_copy:
                atoms.calc = calculator
            all_configurations.append(config_copy)
    #TODO
    # Add other calculators as needed
    return all_configurations

def calculate_std_dev(all_configurations, cache_file=None):
    """
    Calculate the standard deviation of energies for each atom and the mean RMSD of forces
    for each atom across different models, and cache the energies, forces, and configurations 
    to a binary file if specified.

    Parameters:
    - all_configurations (list): List of configurations, where each configuration is a list of ASE Atoms objects
                                 with pre-computed energies and forces already set for different models.
    - cache_file (str): Optional path to a file where the energy values, forces, and configurations will be cached.

    Returns:
    - std_dev (list): A list containing the standard deviation of energies for each atom across the models.
    - mean_rmsd (list): A list containing the mean RMSD of forces for each atom across the models.
    - energy_values (list): A list containing the computed energy values for each atom.
    - force_values (list): A list containing the computed force values for each atom.
    """
    num_atoms = len(all_configurations[0])  # Assume all configurations have the same number of atoms
    energies = [[] for _ in range(num_atoms)]  # To store energies for each atom
    forces = [[] for _ in range(num_atoms)]  # To store forces for each atom

    # Flatten the configurations and atom data for the progress bar
    total_atoms = len(all_configurations) * num_atoms  # Total number of atom-energy/force pairs to process
    progress = tqdm(total=total_atoms, desc="Processing Energies and Forces")

    # Iterate through each configuration and collect energies and forces for each atom
    for config in all_configurations:
        for atom in config:
            energy = atom.get_total_energy()  # Access the energy for each atom
            force = atom.get_forces()  # Access the force for each atom
            atom_index = config.index(atom)
            energies[atom_index].append(energy)  # Store the energy for the corresponding atom
            forces[atom_index].append(np.array(force).flatten())  # Store the force for the corresponding atom
            progress.update(1)  # Update the progress bar after processing each atom

    # Ensure all force arrays have the same shape
    max_length = max(len(f) for atom_forces in forces for f in atom_forces)
    for atom_forces in forces:
        for i in range(len(atom_forces)):
            if len(atom_forces[i]) < max_length:
                atom_forces[i] = np.pad(atom_forces[i], (0, max_length - len(atom_forces[i])), 'constant')

    # Convert energies and forces to numpy arrays for calculations
    energies_array = np.array(energies)
    forces_array = np.array(forces)

    # Calculate the standard deviation of energies for each atom
    std_dev = np.std(energies_array, axis=1).tolist()

    # Calculate the absolute deviation of flattened forces between configurations for each atom
    mean_abs_deviation = []
    for atom_forces in forces_array:
        flattened_forces = atom_forces.reshape(atom_forces.shape[0], -1)  # Flatten the forces for each configuration
        abs_deviation_values = []
        for i in range(len(flattened_forces)):
            for j in range(i + 1, len(flattened_forces)):
                abs_deviation = np.abs(flattened_forces[i] - flattened_forces[j])
                abs_deviation_values.append(np.mean(abs_deviation))  # Mean absolute deviation
        mean_abs_deviation.append(np.mean(abs_deviation_values))  # Mean absolute deviation for each atom

    # Cache energy values, force values, and configurations to a binary file if specified
    if cache_file:
        try:
            # Prepare data to save
            data_to_save = {
                'all_configurations': all_configurations,  # Save all configurations
                'energy_values': energies_array.tolist(),  # Save energies as a list
                'force_values': forces_array.tolist(),  # Save forces as a list
                'std_dev': std_dev,  # Save standard deviations
                'mean_rmsd': mean_abs_deviation  # Save mean RMSD values
            }
            torch.save(data_to_save, cache_file)
            logging.info(f"Energy values, force values, RMSD, and configurations saved to {cache_file}.")

            # Reload in CPU mode (if necessary) and re-save
            cpu_data = torch.load(cache_file, map_location='cpu')
            torch.save(cpu_data, cache_file)
            logging.info(f"Data re-saved to {cache_file} in CPU-compatible format.")

        except Exception as e:
            logging.error(f"Error processing cache file: {e}")

    return std_dev, mean_abs_deviation, energies_array.tolist(), forces_array.tolist()  # Return std dev, RMSD, energy, and force values

def filter_high_deviation_structures(atoms_lists, std_dev, user_threshold=None, lower_threshold=None, percentile=90):
    """
    Filters structures based on the normalized standard deviation.
    Includes structures with normalized deviation within the specified threshold range.

    Parameters:
    - atoms_lists (list of list of ASE Atoms): List containing multiple atoms lists for each model.
    - energies (list of list of floats): List containing energies for each model.
    - std_dev (list of floats): Standard deviation values.
    - user_threshold (float, optional): User-defined upper threshold for filtering. If None, percentile-based threshold is used.
    - lower_threshold (float, optional): User-defined lower threshold for filtering. If None, no lower threshold is applied.
    - percentile (int): Percentile threshold for filtering if no user threshold is provided.

    Returns:
    - filtered_atoms_list (list of ASE Atoms): List of filtered structures.
    - filtered_std_dev (list of floats): List of standard deviation values corresponding to the filtered structures.
    """
    # Compute the normalized standard deviation
    std_dev_normalized = std_dev
    if user_threshold is not None:
        upper_threshold = float(user_threshold)
        logging.info(f"User-defined upper threshold for filtering: {upper_threshold}")
    else:
        upper_threshold = np.percentile(std_dev_normalized, percentile)
        logging.info(f"Threshold for filtering (95th percentile): {upper_threshold}")

    if lower_threshold is not None:
        lower_threshold = float(lower_threshold)
        logging.info(f"User-defined lower threshold for filtering: {lower_threshold}")
    else:
        lower_threshold = float('-inf')  # No lower threshold

    # Filter structures based on the chosen thresholds
    filtered_atoms_list = []
    filtered_std_dev = []
    for i, norm_dev in enumerate(std_dev_normalized):
        if lower_threshold <= norm_dev <= upper_threshold:  # Include structures within the threshold range
            filtered_atoms_list.append(atoms_lists[0][i])
            filtered_std_dev.append(norm_dev)
    logging.info(f"Number of structures within threshold range: {len(filtered_atoms_list)}")
    return filtered_atoms_list, filtered_std_dev

def plot_std_dev_distribution(std_devs):
    """
    Plots the distribution of standard deviations using a histogram.

    Parameters:
    - std_devs (list): List of standard deviation values to plot.
    """
    plt.figure(figsize=(10, 6))
    plt.hist(std_devs, bins=20, edgecolor='black', alpha=0.7)
    plt.title('Distribution of Standard Deviations')
    plt.xlabel('Standard Deviation')
    plt.ylabel('Frequency')
    plt.axvline(x=np.percentile(std_devs, 98), color='r', linestyle='--', label='98th Percentile')
    plt.legend()
    plt.grid(True)
    plt.show()

def write_qe_file(output_directory, crystal_structure):
    # Define QE input parameters
    input_data = {
        "calculation": "scf",
        "prefix": "qe_input",
        "pseudo_dir": "~/QE/pseudo",
        "outdir": "./out/",
        "verbosity": "high",
        "etot_conv_thr": 1.0e-03,
        "tstress": True,
        "tprnfor": True,
        "degauss": 1.4699723600e-02,
        "ecutrho": 600,
        "ecutwfc": 90,
        "vdw_corr": "mbd",
        "occupations": "smearing",
        "smearing": 'cold',
        "electron_maxstep": 80,
        "mixing_beta": 4.0e-01,
    }
    
    # Define pseudopotentials
    pseudos = {
        "Cl": "Cl.upf",
        "O": "O.upf",
        "F": "F.upf",
        "I": "I.upf",
        "Br": "Br.upf",
        "La": "La.upf",
        "Li": "Li.upf",
        "Zr": "Zr.upf",
        "C" : "C.upf",
        "H" : "H.upf",
        "Nb": "Nb.upf",
    }

    # Create the output directory if it does not exist
    os.makedirs(output_directory, exist_ok=True)
    
    # Write the QE input file using ASE's write function
    filename = os.path.join(output_directory, "qe_input.in")
    write(
        format='espresso-in',
        filename=filename,
        images=crystal_structure, 
        input_data=input_data,
        pseudopotentials=pseudos,
        kspacing=0.05
    )

def main():
    # Parse command-line arguments
    args = parse_arguments()
    device = args.device
    calculator = args.calculator
    logging.info(f"Using calculator: {calculator}")
    logging.info(f"Device selected: {device}")
    # Create the output directory if it doesn't exist
    os.makedirs(args.output_dir, exist_ok=True)

    logging.info(f"This is the current Pytorch version you are using {torch.__version__}")
    logging.info(f" Is cuda available? {torch.cuda.is_available()}")    

    if torch.cuda.is_available():
        logging.info(f"Using GPU: {torch.cuda.get_device_name(0)}")
    
    # Get the configuration space based on the provided file or directory
    atoms_list = get_configuration_space(args.filepath, args.stepsize)
    models = load_models(args.model_dir, calculator=args.calculator, device=device)

    # Print the number of configurations loaded
    logging.info(f"Number of configurations loaded: {len(atoms_list)}")
    logging.info(f"Models loaded: {models}")

    # Calculate energies and standard deviation, using cache if specified
    atoms_list = assign_calculator(
        configurations=atoms_list,
        models=models,
        device=device,
        calculator = calculator
        # Pass the user-defined cache file path or None if not provided
    )
    logging.info(f"Running calculations on {len(atoms_list)} configurations.")
    std_dev, mean_abs_deviation, energies_array, forces_array = calculate_std_dev(atoms_list,cache_file=args.use_cache)
    logging.info(f"Standard deviations calculated for {len(std_dev)} atoms.")
    
        # Plot the distribution of standard deviations if the flag is set
    if args.plot_std_dev:
        plot_std_dev_distribution(std_dev)

    # Use user-defined threshold to filter high-deviation structures
    if args.eval_criteria == 'energy':
        logging.info(f"Filtering structures based on energy standard deviation.")
        filtered_atoms_list, filtered_std_dev = filter_high_deviation_structures(
            atoms_lists=atoms_list,
            std_dev=std_dev,
            user_threshold=args.threshold,
            lower_threshold=args.lower_threshold
            )
    elif args.eval_criteria == 'forces':
        logging.info(f"Filtering structures based on forces standard deviation.")
        filtered_atoms_list, filtered_std_dev = filter_high_deviation_structures(
            atoms_lists=atoms_list,
            std_dev=mean_abs_deviation,
            user_threshold=args.threshold,
            lower_threshold=args.lower_threshold
            )
    logging.info(f"Number of filtered structures: {len(filtered_atoms_list)}")

    # Write input files for the filtered structures based on DFT software choice
    for idx, atoms in enumerate(filtered_atoms_list):
        # Define the subdirectory for each filtered structure
        structure_output_dir = os.path.join(args.output_dir, f"structure_{idx}")
        os.makedirs(structure_output_dir, exist_ok=True)

        # Write the appropriate input file based on the chosen DFT software
        if args.dft_software:
            if args.dft_software.lower() == 'qe':
                write_qe_file(structure_output_dir, atoms)
            else:
                logging.error(f"Unsupported DFT software: {args.dft_software}")

if __name__ == "__main__":
    main()
